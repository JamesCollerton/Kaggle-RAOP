fibonacci_reg <- function(fib_vec, num_initial_steps){
if(num_initial_steps == 0){
fib_vec[length(fib_vec) + 1] <- 0
return(0)
}
else if(num_initial_steps == 1){
fib_vec[length(fib_vec) + 1] <- 1
return(1)
}
else{
fib_vec[length(fib_vec) + 1] <- num_initial_steps
return(fibonacci_reg(num_initial_steps - 1) + fibonacci_reg(num_initial_steps - 2))
}
}
fibonacci_reg <- function(fib_vec, num_initial_steps){
if(num_initial_steps == 0){
fib_vec[length(fib_vec) + 1] <- 0
return(0)
}
else if(num_initial_steps == 1){
print(fib_vec)
fib_vec[length(fib_vec) + 1] <- 1
return(1)
}
else{
fib_vec[length(fib_vec) + 1] <- num_initial_steps
return(fibonacci_reg(num_initial_steps - 1) + fibonacci_reg(num_initial_steps - 2))
}
}
fibonacci_reg(c(), 7)
empty_vec <- c()
fibonacci_reg(empty_vec, 7)
fibonacci_reg <- function(fib_vec, num_initial_steps){
if(num_initial_steps == 0){
fib_vec[length(fib_vec) + 1] <- 0
return(0)
}
else if(num_initial_steps == 1){
print(fib_vec)
fib_vec[length(fib_vec) + 1] <- 1
return(1)
}
else{
fib_vec[length(fib_vec) + 1] <- num_initial_steps
return(fibonacci_reg(fib_vec, num_initial_steps - 1) + fibonacci_reg(fib_vec, num_initial_steps - 2))
}
}
fibonacci_reg(empty_vec, 7)
difftime(as.Date("2009-10-01 10:00"), as.Date("2009-10-01 9:00"), "hours")
difftime(as.Date("2009-10-01 10:00"), as.Date("2009-10-01 9:00"), units = "hours")
as.Date("2009-10-01 10:00"
as.Date("2009-10-01 10:00")
as.Date("2009-10-01 10:00")
as.POSIXct("2009-10-01 10:00", format="%m/%d/%y %H:%M")
as.POSIXct("2009-10-01 10:00", format="%y/%n/%d %H:%M")
as.POSIXct("2009-10-01 10:00", format="%y-%n-%d %H:%M")
as.POSIXt("2009-10-01 10:00", format="%y-%n-%d %H:%M")
as.POSIXct("2009-10-01 10:00", format="%y-%n-%d %H:%M")
as.POSIXct("2009-10-01 10:00", format="%yyyy-%mm-%dd %HH:%MM")
as.POSIXct(strptime("2011-03-27 01:30:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("2009-10-01 01:30:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("2009-10-01 01:30:00", "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime("2009-09-01 01:30:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("2009-10-01 01:30:00", "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime("2009-09-01 01:29:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("2009-10-01 01:30:00", "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime("2009-09-01 01:28:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("2009-10-01 01:30:00", "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime("2009-09-01 01:28:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("2009-10-01 10:00:00", "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime("2009-09-01 09:00:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("2009-10-01 10:00:00", "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime("2009-10-01 09:00:00", "%Y-%m-%d %H:%M:%S"))
as.POSIXct(strptime("29/12/2014 10:00:00", "%d/%m/%Y %H:%M:%S")) - as.POSIXct(strptime("29/12/2014 08:00:00", "%d/%m/%Y %H:%M:%S"))
as.POSIXct("2009-10-01 10:00:00", "%Y-%m-%d %H:%M:%S") -
as.POSIXct("2009-10-01 09:00:00", "%Y-%m-%d %H:%M:%S")
as.POSIXct("2009-10-01 10:00:00", "%Y-%m-%d %H:%M:%S") -
as.POSIXct("2009-10-01 09:00:00", "%Y-%m-%d %H:%M:%S")
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- as.dataframe(Date, Value)
dateDataframe <- as.data.frame(Date, Value)
dateDataframe <- as.data.frame(c(Date, Value))
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- as.data.frame(c(Date, Value))
dateDataframe
dateDataframe <- as.data.frame(Date, Value)
Date_Col <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value_Col <- c(0, 1, 2)
dateDataframe <- as.data.frame(Date_Col, Value_Col)
Date_Col <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value_Col <- c(0, 1, 2)
dateDataframe <- as.data.frame(Date_Col, Value_Col, row.names = NULL)
dateDataframe <- data.frame(Date_Col, Value_Col)
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- data.frame(Date, Value)
dateDataframe
dateDataframe%dateDifferences <- diff(dateDataframe$Date)
diff(dateDataframe$Date)
dateDifferences <- as.POSIXct(strptime(dateDataframe$Date, "%Y-%m-%d %H:%M:%S")) - as.POSIXct(strptime(dateDataframe$Date, "%Y-%m-%d %H:%M:%S"))
dateDifferences
dateDifferences <- as.POSIXct(strptime(dateDataframe$Date[2:nrow(dateDataframe)], "%Y-%m-%d %H:%M:%S")) - as.POSIXct(strptime(dateDataframe$Date[1:nrow(dateDataframe) - 1], "%Y-%m-%d %H:%M:%S"))
dateDifferences
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- data.frame(Date, Value)
dateDifferences <- c(0,
as.POSIXct(strptime(dateDataframe$Date[1:nrow(dateDataframe) - 1], "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime(dateDataframe$Date[2:nrow(dateDataframe)], "%Y-%m-%d %H:%M:%S")) )
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- data.frame(Date, Value)
dateDataframe$dateDifferences <- c(0,
as.POSIXct(strptime(dateDataframe$Date[1:nrow(dateDataframe) - 1], "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime(dateDataframe$Date[2:nrow(dateDataframe)], "%Y-%m-%d %H:%M:%S")) )
dateDataframe
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- data.frame(Date, Value)
dateDataframe$dateDifferences <- c(0,
as.string(
as.POSIXct(strptime(dateDataframe$Date[1:nrow(dateDataframe) - 1], "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime(dateDataframe$Date[2:nrow(dateDataframe)], "%Y-%m-%d %H:%M:%S")) ) )
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- data.frame(Date, Value)
dateDataframe$dateDifferences <- c(0,
toString(
as.POSIXct(strptime(dateDataframe$Date[1:nrow(dateDataframe) - 1], "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime(dateDataframe$Date[2:nrow(dateDataframe)], "%Y-%m-%d %H:%M:%S")) ) )
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- data.frame(Date, Value)
dateDataframe$dateDifferences <- c(0,
(
as.POSIXct(strptime(dateDataframe$Date[1:nrow(dateDataframe) - 1], "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime(dateDataframe$Date[2:nrow(dateDataframe)], "%Y-%m-%d %H:%M:%S")) ) )
Date <- c("2009-10-01 10:00:00", "2009-10-01 09:00:00", "2009-10-01 08:00:00")
Value <- c(0, 1, 2)
dateDataframe <- data.frame(Date, Value)
dateDataframe$dateDifferences <- c(0,
as.POSIXct(strptime(dateDataframe$Date[1:nrow(dateDataframe) - 1], "%Y-%m-%d %H:%M:%S")) -
as.POSIXct(strptime(dateDataframe$Date[2:nrow(dateDataframe)], "%Y-%m-%d %H:%M:%S")) )
dateDataframe$dateDifferences[1]
dateDataframe$dateDifferences[2]
dateDataframe$dateDifferences[3]
xvals <- unique(as.numeric(colnames(upvote_table)))
yvals <- upvote_table["TRUE",]/(upvote_table["TRUE",] + upvote_table["FALSE",])
library('tm')
library("rjson")
library("KernSmooth")
library('SnowballC')
library('wordcloud')
setwd("~/Documents/Programming/Git_Folders/Kaggle-RAOP/Updated_Attempt/Data")
#Reads in the relevant .json file
meta_data <- fromJSON(file = "train.json")
#This part just makes a nice dataframe and gives nice titles.
meta_dataframe <- data.frame("giver_username_if_known" = unlist(lapply(meta_data, function(l) l[[1]])),
"number_of_downvotes_of_request_at_retrieval" = unlist(lapply(meta_data, function(l) l[[2]])),
"number_of_upvotes_of_request_at_retrieval" = unlist(lapply(meta_data, function(l) l[[3]])),
"post_was_edited" = unlist(lapply(meta_data, function(l) l[[4]])),
"request_id" = unlist(lapply(meta_data, function(l) l[[5]])),
"request_number_of_comments_at_retrieval" = unlist(lapply(meta_data, function(l) l[[6]])),
"request_text" = unlist(lapply(meta_data, function(l) l[[7]])),
"request_text_edit_aware" = unlist(lapply(meta_data, function(l) l[[8]])),
"request_title" = unlist(lapply(meta_data, function(l) l[[9]])),
"requester_account_age_in_days_at_request" = unlist(lapply(meta_data, function(l) l[[10]])),
"requester_account_age_in_days_at_retrieval" = unlist(lapply(meta_data, function(l) l[[11]])),
"requester_days_since_first_post_on_raop_at_request" = unlist(lapply(meta_data, function(l) l[[12]])),
"requester_days_since_first_post_on_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[13]])),
"requester_number_of_comments_at_request" = unlist(lapply(meta_data, function(l) l[[14]])),
"requester_number_of_comments_at_retrieval" = unlist(lapply(meta_data, function(l) l[[15]])),
"requester_number_of_comments_in_raop_at_request" = unlist(lapply(meta_data, function(l) l[[16]])),
"requester_number_of_comments_in_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[17]])),
"requester_number_of_posts_at_request" = unlist(lapply(meta_data, function(l) l[[18]])),
"requester_number_of_posts_at_retrieval" = unlist(lapply(meta_data, function(l) l[[19]])),
"requester_number_of_posts_on_raop_at_request" = unlist(lapply(meta_data, function(l) l[[20]])),
"requester_number_of_posts_on_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[21]])),
"requester_number_of_subreddits_at_request" = unlist(lapply(meta_data, function(l) l[[22]])),
"requester_received_pizza" = unlist(lapply(meta_data, function(l) l[[23]])),
"requester_upvotes_minus_downvotes_at_request" = unlist(lapply(meta_data, function(l) l[[25]])),
"requester_upvotes_minus_downvotes_at_retrieval" = unlist(lapply(meta_data, function(l) l[[26]])),
"requester_upvotes_plus_downvotes_at_request" = unlist(lapply(meta_data, function(l) l[[27]])),
"requester_upvotes_plus_downvotes_at_retrieval" = unlist(lapply(meta_data, function(l) l[[28]])),
"requester_username" = unlist(lapply(meta_data, function(l) l[[30]])),
"unix_timestamp_of_request" = unlist(lapply(meta_data, function(l) l[[31]])),
"unix_timestamp_of_request_utc" = unlist(lapply(meta_data, function(l) l[[32]])))
###################################################################
#Exploratory analysis##############################################
###################################################################
###################################################################
#The first trend to be explored is if having a lot of downvotes would lead to a dimished
#probability of recieving pizza.
###################################################################
downvotes <- data.frame(meta_dataframe$requester_received_pizza,
meta_dataframe$number_of_downvotes_of_request_at_retrieval)
#Now what we would expect to see is that as the number of downvotes increases the proportion of
#people recieving pizza = (People who recieved pizza)/ (People who did not recieve pizza) begins
#to decrease
#Creates a tabular version of the data.
downvote_table <- table(downvotes)
xvals <- unique(as.numeric(colnames(downvote_table)))
yvals <- downvote_table["FALSE",]/(downvote_table["TRUE",] + downvote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Downvotes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
#To be honest there doesn't seem to be much of a corellation between the two factors which
#is surprising.
###################################################################
#The second trend to be explored is if having a lot of upvotes would lead to a risen
#probability of recieving pizza.
###################################################################
upvotes <- data.frame(meta_dataframe$requester_received_pizza,
meta_dataframe$number_of_upvotes_of_request_at_retrieval)
#Now what we would expect to see is that as the number of upvotes increases the proportion of
#people recieving pizza = (People who recieved pizza)/ (People who did not recieve pizza) begins
#to decrease
#Creates a tabular version of the data.
upvote_table <- table(upvotes)
xvals <- unique(as.numeric(colnames(upvote_table)))
yvals <- upvote_table["TRUE",]/(upvote_table["TRUE",] + upvote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of upvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of upvotes
and Proportion of Successful Pizza Requests", pch = 16)
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
source('~/Documents/Programming/Git_Folders/Kaggle-RAOP/Updated_Attempt/RAOP_Analysis.R', echo=TRUE)
total_attention <- meta_dataframe$requester_upvotes_plus_downvotes_at_retrieval +
meta_dataframe$request_number_of_comments_at_retrieval
total_attention_df <- data.frame(total_attention, meta_dataframe$requester_received_pizza)
plot(total_attention_df$meta_dataframe.requester_received_pizza, total_attention_df$total_attention)
plot(total_attention_df$total_attention, total_attention_df$meta_dataframe.requester_received_pizza)
library('tm')
library("rjson")
library("KernSmooth")
library('SnowballC')
library('wordcloud')
setwd("~/Documents/Programming/Git_Folders/Kaggle-RAOP/Updated_Attempt/Data")
#Reads in the relevant .json file
meta_data <- fromJSON(file = "train.json")
#This part just makes a nice dataframe and gives nice titles.
meta_dataframe <- data.frame("giver_username_if_known" = unlist(lapply(meta_data, function(l) l[[1]])),
"number_of_downvotes_of_request_at_retrieval" = unlist(lapply(meta_data, function(l) l[[2]])),
"number_of_upvotes_of_request_at_retrieval" = unlist(lapply(meta_data, function(l) l[[3]])),
"post_was_edited" = unlist(lapply(meta_data, function(l) l[[4]])),
"request_id" = unlist(lapply(meta_data, function(l) l[[5]])),
"request_number_of_comments_at_retrieval" = unlist(lapply(meta_data, function(l) l[[6]])),
"request_text" = unlist(lapply(meta_data, function(l) l[[7]])),
"request_text_edit_aware" = unlist(lapply(meta_data, function(l) l[[8]])),
"request_title" = unlist(lapply(meta_data, function(l) l[[9]])),
"requester_account_age_in_days_at_request" = unlist(lapply(meta_data, function(l) l[[10]])),
"requester_account_age_in_days_at_retrieval" = unlist(lapply(meta_data, function(l) l[[11]])),
"requester_days_since_first_post_on_raop_at_request" = unlist(lapply(meta_data, function(l) l[[12]])),
"requester_days_since_first_post_on_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[13]])),
"requester_number_of_comments_at_request" = unlist(lapply(meta_data, function(l) l[[14]])),
"requester_number_of_comments_at_retrieval" = unlist(lapply(meta_data, function(l) l[[15]])),
"requester_number_of_comments_in_raop_at_request" = unlist(lapply(meta_data, function(l) l[[16]])),
"requester_number_of_comments_in_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[17]])),
"requester_number_of_posts_at_request" = unlist(lapply(meta_data, function(l) l[[18]])),
"requester_number_of_posts_at_retrieval" = unlist(lapply(meta_data, function(l) l[[19]])),
"requester_number_of_posts_on_raop_at_request" = unlist(lapply(meta_data, function(l) l[[20]])),
"requester_number_of_posts_on_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[21]])),
"requester_number_of_subreddits_at_request" = unlist(lapply(meta_data, function(l) l[[22]])),
"requester_received_pizza" = unlist(lapply(meta_data, function(l) l[[23]])),
"requester_upvotes_minus_downvotes_at_request" = unlist(lapply(meta_data, function(l) l[[25]])),
"requester_upvotes_minus_downvotes_at_retrieval" = unlist(lapply(meta_data, function(l) l[[26]])),
"requester_upvotes_plus_downvotes_at_request" = unlist(lapply(meta_data, function(l) l[[27]])),
"requester_upvotes_plus_downvotes_at_retrieval" = unlist(lapply(meta_data, function(l) l[[28]])),
"requester_username" = unlist(lapply(meta_data, function(l) l[[30]])),
"unix_timestamp_of_request" = unlist(lapply(meta_data, function(l) l[[31]])),
"unix_timestamp_of_request_utc" = unlist(lapply(meta_data, function(l) l[[32]])))
###################################################################
#Exploratory analysis##############################################
###################################################################
###################################################################
#The first trend to be explored is if having a lot of downvotes would lead to a dimished
#probability of recieving pizza.
###################################################################
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(downvotes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Downvotes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
library('tm')
library("rjson")
library("KernSmooth")
library('SnowballC')
library('wordcloud')
setwd("~/Documents/Programming/Git_Folders/Kaggle-RAOP/Updated_Attempt/Data")
#Reads in the relevant .json file
meta_data <- fromJSON(file = "train.json")
#This part just makes a nice dataframe and gives nice titles.
meta_dataframe <- data.frame("giver_username_if_known" = unlist(lapply(meta_data, function(l) l[[1]])),
"number_of_downvotes_of_request_at_retrieval" = unlist(lapply(meta_data, function(l) l[[2]])),
"number_of_upvotes_of_request_at_retrieval" = unlist(lapply(meta_data, function(l) l[[3]])),
"post_was_edited" = unlist(lapply(meta_data, function(l) l[[4]])),
"request_id" = unlist(lapply(meta_data, function(l) l[[5]])),
"request_number_of_comments_at_retrieval" = unlist(lapply(meta_data, function(l) l[[6]])),
"request_text" = unlist(lapply(meta_data, function(l) l[[7]])),
"request_text_edit_aware" = unlist(lapply(meta_data, function(l) l[[8]])),
"request_title" = unlist(lapply(meta_data, function(l) l[[9]])),
"requester_account_age_in_days_at_request" = unlist(lapply(meta_data, function(l) l[[10]])),
"requester_account_age_in_days_at_retrieval" = unlist(lapply(meta_data, function(l) l[[11]])),
"requester_days_since_first_post_on_raop_at_request" = unlist(lapply(meta_data, function(l) l[[12]])),
"requester_days_since_first_post_on_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[13]])),
"requester_number_of_comments_at_request" = unlist(lapply(meta_data, function(l) l[[14]])),
"requester_number_of_comments_at_retrieval" = unlist(lapply(meta_data, function(l) l[[15]])),
"requester_number_of_comments_in_raop_at_request" = unlist(lapply(meta_data, function(l) l[[16]])),
"requester_number_of_comments_in_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[17]])),
"requester_number_of_posts_at_request" = unlist(lapply(meta_data, function(l) l[[18]])),
"requester_number_of_posts_at_retrieval" = unlist(lapply(meta_data, function(l) l[[19]])),
"requester_number_of_posts_on_raop_at_request" = unlist(lapply(meta_data, function(l) l[[20]])),
"requester_number_of_posts_on_raop_at_retrieval" = unlist(lapply(meta_data, function(l) l[[21]])),
"requester_number_of_subreddits_at_request" = unlist(lapply(meta_data, function(l) l[[22]])),
"requester_received_pizza" = unlist(lapply(meta_data, function(l) l[[23]])),
"requester_upvotes_minus_downvotes_at_request" = unlist(lapply(meta_data, function(l) l[[25]])),
"requester_upvotes_minus_downvotes_at_retrieval" = unlist(lapply(meta_data, function(l) l[[26]])),
"requester_upvotes_plus_downvotes_at_request" = unlist(lapply(meta_data, function(l) l[[27]])),
"requester_upvotes_plus_downvotes_at_retrieval" = unlist(lapply(meta_data, function(l) l[[28]])),
"requester_username" = unlist(lapply(meta_data, function(l) l[[30]])),
"unix_timestamp_of_request" = unlist(lapply(meta_data, function(l) l[[31]])),
"unix_timestamp_of_request_utc" = unlist(lapply(meta_data, function(l) l[[32]])))
###################################################################
#Exploratory analysis##############################################
###################################################################
###################################################################
#The first trend to be explored is if having a lot of downvotes would lead to a dimished
#probability of recieving pizza.
###################################################################
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Downvotes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Downvotes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
yvals <- yvals[!yvals %in% boxplot.stats(yvals)$out]
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Downvotes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
xvals <- xvals[!yvals %in% boxplot.stats(yvals)$out]
yvals <- yvals[!yvals %in% boxplot.stats(yvals)$out]
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
xvals <- xvals[!yvals %in% boxplot.stats(yvals)$out]
yvals <- yvals[!yvals %in% boxplot.stats(yvals)$out]
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Downvotes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
xvals <- xvals[yvals > 0]
yvals <- yvals[yvals > 0]
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
xvals <- xvals[yvals < 1]
yvals <- yvals[yvals < 1]
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
downvote_table
downvote_table[downvote_table > 9]
downvote_table[downvote_table > 9,]
downvote_table[,downvote_table > 9]
downvote_table > 9
downvote_table[1,] > 9
downvote_table[2,] > 9
