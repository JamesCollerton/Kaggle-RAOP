xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
true_data <- vote_table["TRUE",]
true_mean <- mean(true_data)
true_sd <- sd(true_data)
print(qnorm(0.05, true_mean, true_sd))
sufficient_data <- intersect(which(vote_table["FALSE",] > 9), which(vote_table["TRUE",] > 9))
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
sufficient_data <- intersect(which(vote_table["FALSE",] > 9), which(vote_table["TRUE",] > 9))
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval)
check_voting_impact <- function(vote_type, sufficient_data_threshold)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
sufficient_data <- intersect(which(vote_table["FALSE",] > sufficient_data_threshold), which(vote_table["TRUE",] > sufficient_data_threshold))
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval, 9)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval, 4)
check_voting_impact <- function(vote_type, sufficient_data_threshold)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
false_sufficient_data <- which(vote_table["FALSE",] > sufficient_data_threshold)
true_sufficient_data <- which(vote_table["TRUE",] > sufficient_data_threshold)
sufficient_data <- intersect(false_sufficient_data, true_sufficient_data)
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval, 9)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval, 4)
check_voting_impact <- function(vote_type, sufficient_data_threshold)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
false_sufficient_data <- which(vote_table["FALSE",] > sufficient_data_threshold)
true_sufficient_data <- which(vote_table["TRUE",] > sufficient_data_threshold)
sufficient_data <- intersect(false_sufficient_data, true_sufficient_data)
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval, 9)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval, 5)
check_voting_impact <- function(vote_type, sufficient_data_threshold)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
false_sufficient_data <- which(vote_table["FALSE",] > sufficient_data_threshold)
true_sufficient_data <- which(vote_table["TRUE",] > sufficient_data_threshold)
sufficient_data <- intersect(false_sufficient_data, true_sufficient_data)
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval, 4)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval, 9)
check_voting_impact <- function(vote_type, sufficient_data_threshold)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
false_sufficient_data <- which(vote_table["FALSE",] > sufficient_data_threshold)
true_sufficient_data <- which(vote_table["TRUE",] > sufficient_data_threshold)
sufficient_data <- intersect(false_sufficient_data, true_sufficient_data)
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval, 4)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval, 20)
check_voting_impact <- function(vote_type, sufficient_data_threshold)
{
votes <- data.frame(meta_dataframe$requester_received_pizza,
vote_type)
vote_table <- table(votes)
false_sufficient_data <- which(vote_table["FALSE",] > sufficient_data_threshold)
true_sufficient_data <- which(vote_table["TRUE",] > sufficient_data_threshold)
sufficient_data <- intersect(false_sufficient_data, true_sufficient_data)
vote_table <- vote_table[,sufficient_data]
xvals <- unique(as.numeric(colnames(vote_table)))
yvals <- vote_table["TRUE",]/(vote_table["TRUE",] + vote_table["FALSE",])
plot(xvals, yvals, col = "dodgerblue", xlab = "Number of Downvotes",
ylab = "Proportion of Successful Pizza Requests", main = "Corellation between Number of Votes
and Proportion of Successful Pizza Requests", pch = 16)
#Fits a linear model to the data whilst ignoring all values that jet off to infinity.
lm_fit_df <- data.frame(xvals, yvals)
lm_fit_df <- lm_fit_df[which(lm_fit_df$yvals != Inf),]
fit <- lm(lm_fit_df$yvals ~ lm_fit_df$xvals)
abline(data.frame(summary(fit)$coefficients)$Estimate, col = "firebrick1", lwd = 1.5)
# Finally look at Pearson's.
cor(yvals, xvals, method = "pearson")
}
check_voting_impact(meta_dataframe$number_of_downvotes_of_request_at_retrieval, 7)
check_voting_impact(meta_dataframe$number_of_upvotes_of_request_at_retrieval, 8)
requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == TRUE),]
titles <- requests$request_title
new_titles <- list()
for (i in 1:length(titles)){
new_titles[[i]] <- unlist(strsplit(as.vector(titles[i]), " "))
}
all_title_words = unlist(new_titles)
all_title_words_table_df <- data.frame(table(all_title_words))
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == TRUE),]
titles <- requests$request_title
new_titles <- list()
for (i in 1:length(titles)){
new_titles[[i]] <- unlist(strsplit(as.vector(titles[i]), " "))
}
all_title_words = unlist(new_titles)
all_title_words_table_df <- data.frame(table(all_title_words))
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- readLines(words_page)
useful_words = words_page[92:191]
for (i in 1:length(useful_words)){
useful_words[i] = strsplit(useful_words[i], "<")[[1]][1]
useful_words[i] = strsplit(useful_words[i], " ")[[1]][2]
}
useful_words = c(useful_words, "is", "Pizza", "pizza", "[Request]", "[REQUEST]", "[request]", "-")
all_title_words_table_df <- all_title_words_table_df[-which(all_title_words_table_df$all_title_words %in% useful_words),]
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
#This gives us something to look at and play with. Now we try using the text mining package to
#create a word cloud.
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, content_transformer(tolower))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, content_transformer(tolower))
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, content_transformer(tolower))
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(corpus, PlainTextDocument)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, PlainTextDocument)
# for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, PlainTextDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
create_word_cloud <- function(requests){
titles <- requests$request_title
new_titles <- list()
for (i in 1:length(titles)){
new_titles[[i]] <- unlist(strsplit(as.vector(titles[i]), " "))
}
all_title_words = unlist(new_titles)
all_title_words_table_df <- data.frame(table(all_title_words))
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- readLines(words_page)
useful_words = words_page[92:191]
for (i in 1:length(useful_words)){
useful_words[i] = strsplit(useful_words[i], "<")[[1]][1]
useful_words[i] = strsplit(useful_words[i], " ")[[1]][2]
}
useful_words = c(useful_words, "is", "Pizza", "pizza", "[Request]", "[REQUEST]", "[request]", "-")
all_title_words_table_df <- all_title_words_table_df[-which(all_title_words_table_df$all_title_words %in% useful_words),]
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
#This gives us something to look at and play with. Now we try using the text mining package to
#create a word cloud.
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, PlainTextDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
}
successful_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == TRUE),]
failed_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == FALSE),]
create_word_cloud(successful_requests)
create_word_cloud(failed_requests)
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- readLines(words_page)
library('httr')
required_packages <- c("tm", "rjson", "KernSmooth", "SnowballC", "wordcloud", "httr")
install.packages(required_packages)
install.packages(required_packages)
library('tm')
library("rjson")
library("KernSmooth")
library('SnowballC')
library('wordcloud')
library('httr')
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
content(GET(words_page))
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
setInternet2(TRUE)
readLines(words_page)
library('XML')
install.packages("XML")
library('XML')
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
content(GET(words_page))
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- content(GET(words_page))
useful_words = words_page[92:191]
words_page
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- content(GET(words_page))
words_page <- htmlParse(words_page, asText = TRUE)
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- getURL(words_page))
words_page <- htmlParse(words_page, asText = TRUE)
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- getURL(words_page)
words_page <- htmlParse(words_page, asText = TRUE)
install.packages("RCurl")
library('RCurl')
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- getURL(words_page)
words_page <- htmlParse(words_page, asText = TRUE)
useful_words = words_page[92:191]
words_page
setinternet2(TRUE)
setInternet2(TRUE)
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- getURL(words_page)
words_page <- htmlParse(words_page, asText = TRUE)
words_page
words_page <- "http://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- getURL(words_page)
words_page <- htmlParse(words_page, asText = TRUE)
words_page <- "http://www.englishclub.com/vocabulary/common-words-100.htm"
#   words_page <- getURL(words_page)
words_page <- readlines(words_page)
words_page <- "http://www.englishclub.com/vocabulary/common-words-100.htm"
#   words_page <- getURL(words_page)
words_page <- readLines(words_page)
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- getURL(words_page)
words_page <- htmlParse(words_page, asText = TRUE)
words_page <- "https://www.englishclub.com/vocabulary/common-words-100.htm"
words_page <- getURLContent(words_page)
words_page <- htmlParse(words_page, asText = TRUE)
words_page
words_page <- "https://en.wikipedia.org/wiki/Most_common_words_in_English"
words_page <- getURLContent(words_page)
words_page <- htmlParse(words_page, asText = TRUE)
words_page
tables <- readHTMLTable(words_page)
tables
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
n.rows
tables <- readHTMLTable(words_page)
tables
tables$word
tables$Word
tables$'NULL'
tables$'NULL'$Word
str(tables$'NULL')
tables$'NULL'$V2
successful_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == TRUE),]
create_word_cloud <- function(requests){
titles <- requests$request_title
new_titles <- list()
for (i in 1:length(titles)){
new_titles[[i]] <- unlist(strsplit(as.vector(titles[i]), " "))
}
all_title_words = unlist(new_titles)
all_title_words_table_df <- data.frame(table(all_title_words))
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
words_page <- "https://en.wikipedia.org/wiki/Most_common_words_in_English"
tables <- readHTMLTable(words_page)
useful_words <- tables$'NULL'$V2
# useful_words = words_page[92:191]
# for (i in 1:length(useful_words)){
#   useful_words[i] = strsplit(useful_words[i], "<")[[1]][1]
#   useful_words[i] = strsplit(useful_words[i], " ")[[1]][2]
# }
useful_words = c(useful_words, "is", "Pizza", "pizza", "[Request]", "[REQUEST]", "[request]", "-")
all_title_words_table_df <- all_title_words_table_df[-which(all_title_words_table_df$all_title_words %in% useful_words),]
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
#This gives us something to look at and play with. Now we try using the text mining package to
#create a word cloud.
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, PlainTextDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
}
successful_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == TRUE),]
failed_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == FALSE),]
successful_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == TRUE),]
failed_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == FALSE),]
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, PlainTextDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
create_word_cloud <- function(requests){
titles <- requests$request_title
new_titles <- list()
for (i in 1:length(titles)){
new_titles[[i]] <- unlist(strsplit(as.vector(titles[i]), " "))
}
all_title_words = unlist(new_titles)
all_title_words_table_df <- data.frame(table(all_title_words))
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
words_page <- "https://en.wikipedia.org/wiki/Most_common_words_in_English"
tables <- readHTMLTable(words_page)
useful_words <- tables$'NULL'$V2
# useful_words = words_page[92:191]
# for (i in 1:length(useful_words)){
#   useful_words[i] = strsplit(useful_words[i], "<")[[1]][1]
#   useful_words[i] = strsplit(useful_words[i], " ")[[1]][2]
# }
useful_words = c(useful_words, "is", "Pizza", "pizza", "[Request]", "[REQUEST]", "[request]", "-")
all_title_words_table_df <- all_title_words_table_df[-which(all_title_words_table_df$all_title_words %in% useful_words),]
all_title_words_table_df <- all_title_words_table_df[order(all_title_words_table_df$Freq),]
#This gives us something to look at and play with. Now we try using the text mining package to
#create a word cloud.
for_word_cloud_corpus <- Corpus(VectorSource(all_title_words_table_df$all_title_words))
#cleaning
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stripWhitespace)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, tolower)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, PlainTextDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, stopwords("english"))
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, stemDocument)
for_word_cloud_corpus <- tm_map(for_word_cloud_corpus, removeWords, c("[request]", "request"))
wordcloud(for_word_cloud_corpus, scale = c(4, 1), max.words = 100, colors = brewer.pal(8, "Dark2"))
}
successful_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == TRUE),]
failed_requests <- meta_dataframe[which(meta_dataframe$requester_received_pizza == FALSE),]
create_word_cloud(successful_requests)
create_word_cloud(failed_requests)
